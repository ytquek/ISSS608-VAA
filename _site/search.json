[
  {
    "objectID": "take_home_ex/take_home_ex3.html",
    "href": "take_home_ex/take_home_ex3.html",
    "title": "Take Home 3",
    "section": "",
    "text": "The task is taken from the VAST Challenge 2024. Questions from Mini Case 1 will be completed."
  },
  {
    "objectID": "take_home_ex/take_home_ex3.html#background",
    "href": "take_home_ex/take_home_ex3.html#background",
    "title": "Take Home 3",
    "section": "Background",
    "text": "Background\nIn Oceanus, commercial fishing is a major part of the local economy, and the activities of local fishing companies are often discussed in local news reports, especially when there is a major disruption or controversial issue. Lately, the news is filled with stories of companies who are willing to break the law and fish illegally.\nFishEye International is an organization whose mission is to discover and stop illegal, unreported, and unregulated fishing. FishEye is an independent non-profit, but they share their findings with law enforcement when warranted. FishEye analysts collect open-source data, including news articles and public reports, and have recently started extracting embedded knowledge from these free text sources using several advanced language models. Knowledge from multiple sources is combined to form CatchNet: the Oceanus Knowledge Graph, which is used to search for evidence of possible illegal fishing activity. Analysts know that data may be biased so they review and edit extracted information before it is added to CatchNet. Data for this challenge includes both the extracted and analyst modified knowledge graph and the original source articles.\nRecently, the commercial fishing community in Oceanus was rocked with scandal after SouthSeafood Express Corp was caught fishing illegally. The company’s leaders claim an innocent mistake, while others in the industry have suggested getting caught was overdue and is likely part of a larger pattern of suspect behavior. FishEye analysts are aware that a polarizing event like this is likely to attract biased perspectives. They are looking for your help to identify sources of bias in their data. They are having particular trouble determining whether bias comes from the source article, the algorithms used to extract the knowledge graph, or possibly somewhere else…"
  },
  {
    "objectID": "take_home_ex/take_home_ex3.html#tasks-and-questions",
    "href": "take_home_ex/take_home_ex3.html#tasks-and-questions",
    "title": "Take Home 3",
    "section": "Tasks and Questions:",
    "text": "Tasks and Questions:\nYour task is to develop visual analytics approaches that FishEye analysts can use to verify the facts included in their knowledge graph are representative of facts stated in the source text. Analysts should be able to compare consistency of the extracted knowledge with the source and identify and trace sources of bias in the data. Novel use of large language models (LLMs) as part of a visual analytics process is encouraged.\n\nUse novel visualizations and visual analytic workflows to examine the bias in each news source. Create visualizations to help FishEye analysts understand how bias in the original sources changes over time. You may use the knowledge graph extracts and may use a large language model to supplement your understanding.\nFishEye uses two LLM extraction algorithms: ShadGPT and BassLine. Develop visualizations to compare the bias of each algorithm. Though not required, you may develop your own LLM-based extraction and include it in the comparison.\nFishEye is also interested in understanding the reliability of their human analysts. Use visual analytics to examine potential analyst bias. Provide visual examples of the types of bias present.\nIdentify unreliable actors: news sources, algorithms, or analysts. Use visualizations to provide evidence for your conclusions. Can you use the data provided and a visual analytics workflow to determine who else may be involved?\n\nNote: the VAST challenge is focused on visual analytics and graphical figures should be included with your response to each question. Please include a reasonable number of figures for each question (no more than about 6) and keep written responses as brief as possible (around 250 words per question). Participants are encouraged to new visual representations rather than relying on traditional or existing approaches."
  },
  {
    "objectID": "take_home_ex/take_home_ex3.html#installing-and-loading-the-required-libraries",
    "href": "take_home_ex/take_home_ex3.html#installing-and-loading-the-required-libraries",
    "title": "Take Home 3",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nNote: Ensure that the pacman package has already been installed.\nThe following R packages will be used:\n\ntidytext, tidyverse\nreadtext\nquanteda\n\n\npacman::p_load(tidytext, readtext, quanteda, tidytext, tidyverse)"
  },
  {
    "objectID": "take_home_ex/take_home_ex3.html#importing-multiple-text-files",
    "href": "take_home_ex/take_home_ex3.html#importing-multiple-text-files",
    "title": "Take Home 3",
    "section": "Importing Multiple Text Files",
    "text": "Importing Multiple Text Files\n\nCreating a folder list\n\ndata_folder &lt;- \"data/articles/\"\n\n\n\nDefine a function to read all files from a folder into a data frame\n\ntext_data &lt;- readtext(paste0(\"data/articles\",\"/*\"))\n# alternate version: text_data &lt;- readtext(\"data/articles/*\")\n\nCheck dataframe\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\n\n\nText Data Processing\n\n unnest_tokens() of tidytext package is used to split the dataset into tokens\n stop_words() is used to remove stop-words\n\n\n# Tokenize the text column\nunnest_words &lt;- text_data %&gt;%   \n  unnest_tokens(output = word, input = text) \n\n# Filter tokens to include only alphabetic characters and remove stop words\nunnest_words &lt;- filter(unnest_words, \n                       str_detect(word, \"[a-z']$\"),          \n                       !word %in% stop_words$word)\n\nView dataframe\n\nglimpse(unnest_words)\n\nRows: 50,147\nColumns: 2\n$ doc_id &lt;chr&gt; \"Alvarez PLC__0__0__Haacklee Herald.txt\", \"Alvarez PLC__0__0__H…\n$ word   &lt;chr&gt; \"marine\", \"sanctuary\", \"aid\", \"boosts\", \"alvarez\", \"plc's\", \"su…\n\n\n\n\nExplore Common words\nThe code chunk below calculates individual word frequencies to explore common words in the dataset.\n\nunnest_words %&gt;%\n  count(word,sort = TRUE)\n\nreadtext object consisting of 3261 documents and 0 docvars.\n# A data frame: 3,261 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,255 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nCommon words from the articles seem to be related to sustainable fishing practices in the larger fishing industry and trade.\n\n\nView dataframe\n\nglimpse(unnest_words)\n\nRows: 50,147\nColumns: 2\n$ doc_id &lt;chr&gt; \"Alvarez PLC__0__0__Haacklee Herald.txt\", \"Alvarez PLC__0__0__H…\n$ word   &lt;chr&gt; \"marine\", \"sanctuary\", \"aid\", \"boosts\", \"alvarez\", \"plc's\", \"su…\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the dataset, it can be seen that under the “doc_id” column, the company mentioned in the article, along with its author is separated by some underscores and numbers. We will split this column into “Company” and “News_Source” to simplify later analysis.\n\n\n\n\nSplit doc_id column\nThe column has the format Company__Number__Number__News_Source.txt.\n\ntext_data_split &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__\",\n                       names = c(\"Company\", \"Number\", \"Number2\", \"News_Source\"),\n                       too_many = \"debug\")\n\nView dataframe\n\nglimpse(text_data_split)\n\nRows: 338\nColumns: 9\n$ Company          &lt;chr&gt; \"Alvarez PLC\", \"Alvarez PLC\", \"Alvarez PLC\", \"Alvarez…\n$ Number           &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\"…\n$ Number2          &lt;chr&gt; \"0\", \"0\", \"0\", \"1\", \"1\", \"1\", \"0\", \"0\", \"0\", \"1\", \"1\"…\n$ News_Source      &lt;chr&gt; \"Haacklee Herald.txt\", \"Lomark Daily.txt\", \"The News …\n$ doc_id           &lt;chr&gt; \"Alvarez PLC__0__0__Haacklee Herald.txt\", \"Alvarez PL…\n$ doc_id_ok        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n$ doc_id_pieces    &lt;int&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ doc_id_remainder &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ text             &lt;chr&gt; \"Marine Sanctuary Aid Boosts Alvarez PLC's Sustainabl…\n\n\nDrop unnecessary columns\n\ntext_data_clean &lt;- text_data_split %&gt;%\n  select(-Number, -Number2, -doc_id, -doc_id_ok, -doc_id_pieces, -doc_id_remainder)\n\nView dataframe\n\nglimpse(text_data_clean)\n\nRows: 338\nColumns: 3\n$ Company     &lt;chr&gt; \"Alvarez PLC\", \"Alvarez PLC\", \"Alvarez PLC\", \"Alvarez PLC\"…\n$ News_Source &lt;chr&gt; \"Haacklee Herald.txt\", \"Lomark Daily.txt\", \"The News Buoy.…\n$ text        &lt;chr&gt; \"Marine Sanctuary Aid Boosts Alvarez PLC's Sustainable Fis…"
  },
  {
    "objectID": "take_home_ex/take_home_ex3.html#eda",
    "href": "take_home_ex/take_home_ex3.html#eda",
    "title": "Take Home 3",
    "section": "EDA",
    "text": "EDA\nList of Company and News Sources\n\nCompaniesNews Sources\n\n\n\n# Unique values in the \"Company\" column\nunique_companies &lt;- unique(text_data_clean$Company)\nunique_companies\n\n [1] \"Alvarez PLC\"                          \n [2] \"Anderson, Brown and Green\"            \n [3] \"Arellano Group\"                       \n [4] \"Barnes and Sons\"                      \n [5] \"Barnett Ltd\"                          \n [6] \"Bell, Reynolds and Forbes\"            \n [7] \"Bishop-Hernandez\"                     \n [8] \"Blackwell, Clark and Lam\"             \n [9] \"Bowers Group\"                         \n[10] \"Brown, Clarke and Martinez\"           \n[11] \"Burns Inc\"                            \n[12] \"Cain, Simpson and Hernandez\"          \n[13] \"Castillo-Elliott\"                     \n[14] \"Cervantes-Kramer\"                     \n[15] \"Cisneros-Meyer\"                       \n[16] \"Clark-Leon\"                           \n[17] \"Clarke, Scott and Sloan\"              \n[18] \"Clements, Allen and Sullivan\"         \n[19] \"Collins, Johnson and Lloyd\"           \n[20] \"Cook PLC\"                             \n[21] \"Cooper, Holland and Nelson\"           \n[22] \"Craig Ltd\"                            \n[23] \"Cuevas PLC\"                           \n[24] \"Davis-Boyd\"                           \n[25] \"Evans-Pearson\"                        \n[26] \"Flores Ltd\"                           \n[27] \"Franco-Stuart\"                        \n[28] \"Frank Group\"                          \n[29] \"Frey Inc\"                             \n[30] \"Glover, Moran and Johnson\"            \n[31] \"Greer-Holder\"                         \n[32] \"Harper Inc\"                           \n[33] \"Harrell-Walters\"                      \n[34] \"Harrington Inc\"                       \n[35] \"Henderson, Hall and Lutz\"             \n[36] \"Hernandez-Rojas\"                      \n[37] \"Hines-Douglas\"                        \n[38] \"Horn and Sons\"                        \n[39] \"Hughes-Clark\"                         \n[40] \"Jackson Inc\"                          \n[41] \"Jones Group\"                          \n[42] \"Jones, Davis and Grant\"               \n[43] \"Kelly-Smith\"                          \n[44] \"Klein LLC\"                            \n[45] \"Lutz-Fleming\"                         \n[46] \"Mann, Myers and Rivera\"               \n[47] \"Martin LLC\"                           \n[48] \"Martinez-Le\"                          \n[49] \"Mcgee and Sons\"                       \n[50] \"Mclaughlin-Chandler\"                  \n[51] \"Montoya Group\"                        \n[52] \"Moore-Simon\"                          \n[53] \"Murphy, Marshall and Pope\"            \n[54] \"Murray, Friedman and Wall\"            \n[55] \"Namorna Transit Ltd\"                  \n[56] \"NyanzaRiver Worldwide AS\"             \n[57] \"Oka Seafood Shipping Ges.m.b.H.\"      \n[58] \"Olsen Group\"                          \n[59] \"Phelps, Brown and Wallace\"            \n[60] \"Phillips-Newton\"                      \n[61] \"PregolyaDredge Logistics Incorporated\"\n[62] \"Ramos-Shelton\"                        \n[63] \"Rasmussen, Nelson and King\"           \n[64] \"Rhodes-Thompson\"                      \n[65] \"Rivas-Stevens\"                        \n[66] \"Rosario-Melendez\"                     \n[67] \"Roth, Logan and Moreno\"               \n[68] \"Sanchez-Moreno\"                       \n[69] \"Serrano-Cruz\"                         \n[70] \"Smith-Hull\"                           \n[71] \"Solis-Lopez\"                          \n[72] \"Spencer, Richards and Wilson\"         \n[73] \"Taylor, Prince and Sherman\"           \n[74] \"Thomas-Weaver\"                        \n[75] \"Thompson-Padilla\"                     \n[76] \"Turner-Green\"                         \n[77] \"Underwood Inc\"                        \n[78] \"V. Miesel Shipping\"                   \n[79] \"Valdez, Dalton and Cook\"              \n[80] \"Vargas-Jensen\"                        \n[81] \"Vasquez, Chaney and Martinez\"         \n[82] \"Walker, Erickson and Blake\"           \n[83] \"Watson-Gray\"                          \n[84] \"Wilcox-Nelson\"                        \n[85] \"Wu-Hart\"                              \n[86] \"York-Castillo\"                        \n\n\n\n\n\n# Unique values in the \"News_Source\" column\nunique_news_sources &lt;- unique(text_data_clean$News_Source)\nunique_news_sources\n\n[1] \"Haacklee Herald.txt\"        \"Lomark Daily.txt\"          \n[3] \"The News Buoy.txt\"          \"Haacklee Herald_Police.txt\"\n[5] \"Lomark Daily_Police.txt\"    \"The News Buoy_Police.txt\"  \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are a total of:\n\n85 companies being mentioned in the news articles\n6 news outlets that authored the news articles\n\n\n\nDiscovering the company that is mentioned the greatest number of times, and the author of the most news articles\n\nCompaniesNews Sources\n\n\n\n# Count the frequency of values in the \"Company\" column and sort by frequency\ncompany_freq &lt;- text_data_clean %&gt;%\n  count(Company) %&gt;%\n  mutate(Percentage = n / sum(n) * 100) %&gt;%\n  arrange(desc(n))\ncompany_freq\n\n# A tibble: 86 × 3\n   Company                        n Percentage\n   &lt;chr&gt;                      &lt;int&gt;      &lt;dbl&gt;\n 1 Cervantes-Kramer              12       3.55\n 2 Jones Group                   12       3.55\n 3 Rasmussen, Nelson and King     8       2.37\n 4 Alvarez PLC                    6       1.78\n 5 Anderson, Brown and Green      6       1.78\n 6 Bell, Reynolds and Forbes      6       1.78\n 7 Blackwell, Clark and Lam       6       1.78\n 8 Brown, Clarke and Martinez     6       1.78\n 9 Burns Inc                      6       1.78\n10 Castillo-Elliott               6       1.78\n# ℹ 76 more rows\n\n\n\n\n\n# Count the frequency of values in the \"News_Source\" column and sort by frequency\nnews_source_freq &lt;- text_data_clean %&gt;%\n  count(News_Source) %&gt;%\n  mutate(Percentage = n / sum(n) * 100) %&gt;%\n  arrange(desc(n))\nnews_source_freq\n\n# A tibble: 6 × 3\n  News_Source                    n Percentage\n  &lt;chr&gt;                      &lt;int&gt;      &lt;dbl&gt;\n1 The News Buoy.txt            112     33.1  \n2 Haacklee Herald.txt          109     32.2  \n3 Lomark Daily.txt             107     31.7  \n4 Haacklee Herald_Police.txt     6      1.78 \n5 Lomark Daily_Police.txt        2      0.592\n6 The News Buoy_Police.txt       2      0.592\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe top 3 companies with the most mentions in the news articles are:\n\nCervantes-Kramer (12 - 33.1%)\nJones GRoup and Rasmussen (12 - 32.2%)\nNelson and King (8 - 31.7%)\n\nThe top 3 news outlets with the most number of news articles are:\n\nThe News Buoy (112 - 33.1%)\nHaacklee Herald (109 - 32.2%)\nLomark Daily (107 - 31.7%)"
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html",
    "href": "take_home_ex/take_home_ex1.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market."
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#data-source",
    "href": "take_home_ex/take_home_ex1.html#data-source",
    "title": "Take Home Exercise 1",
    "section": "Data Source",
    "text": "Data Source\nTo accomplish the task, transaction data of REALIS (2023-2024) will be used."
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#setting-up-the-environment",
    "href": "take_home_ex/take_home_ex1.html#setting-up-the-environment",
    "title": "Take Home Exercise 1",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nInstalling required packages\n\npacman::p_load(tidyverse, ggplot2, dplyr, shiny, bslib)"
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#preparing-the-data",
    "href": "take_home_ex/take_home_ex1.html#preparing-the-data",
    "title": "Take Home Exercise 1",
    "section": "Preparing the data",
    "text": "Preparing the data\n\nRaw Data Import\nGiven that there are 5 sets of Transaction CSV files, we will need to open each and every single one of them using read_csv function before merging them together again into 1 data frame.\n\nCodeOutput\n\n\n\n# Define the paths to the individual CSV files\nfile1 &lt;- \"data/ResidentialTransaction20240308160536.csv\"\nfile2 &lt;- \"data/ResidentialTransaction20240308160736.csv\"\nfile3 &lt;- \"data/ResidentialTransaction20240308161009.csv\"\nfile4 &lt;- \"data/ResidentialTransaction20240308161109.csv\"\nfile5 &lt;- \"data/ResidentialTransaction20240414220633.csv\"\n\n# Reading the individual CSV files\ndata1 &lt;- read_csv(file1)\ndata2 &lt;- read_csv(file2)\ndata3 &lt;- read_csv(file3)\ndata4 &lt;- read_csv(file4)\ndata5 &lt;- read_csv(file5)\n\n# Combining the data frames into one\ncombined_transaction &lt;- bind_rows(data1, data2, data3, data4, data5)\n\n# Viewing the data structure given\ncol_names &lt;- names(combined_transaction)\ncol_names\n\n\n\n\n\n [1] \"Project Name\"                \"Transacted Price ($)\"       \n [3] \"Area (SQFT)\"                 \"Unit Price ($ PSF)\"         \n [5] \"Sale Date\"                   \"Address\"                    \n [7] \"Type of Sale\"                \"Type of Area\"               \n [9] \"Area (SQM)\"                  \"Unit Price ($ PSM)\"         \n[11] \"Nett Price($)\"               \"Property Type\"              \n[13] \"Number of Units\"             \"Tenure\"                     \n[15] \"Completion Date\"             \"Purchaser Address Indicator\"\n[17] \"Postal Code\"                 \"Postal District\"            \n[19] \"Postal Sector\"               \"Planning Region\"            \n[21] \"Planning Area\"              \n\n\n\n\n\nUsing glimpse to ensure our tibble dataframe is correct\n\nglimpse (combined_transaction)\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\nDuplicate checks\n\nCodeOutput\n\n\n\nduplicates &lt;- combined_transaction %&gt;% \n  filter(duplicated(.))\nglimpse(duplicates)\n\n\n\n\n\nRows: 0\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \n$ `Transacted Price ($)`        &lt;dbl&gt; \n$ `Area (SQFT)`                 &lt;dbl&gt; \n$ `Unit Price ($ PSF)`          &lt;dbl&gt; \n$ `Sale Date`                   &lt;chr&gt; \n$ Address                       &lt;chr&gt; \n$ `Type of Sale`                &lt;chr&gt; \n$ `Type of Area`                &lt;chr&gt; \n$ `Area (SQM)`                  &lt;dbl&gt; \n$ `Unit Price ($ PSM)`          &lt;dbl&gt; \n$ `Nett Price($)`               &lt;chr&gt; \n$ `Property Type`               &lt;chr&gt; \n$ `Number of Units`             &lt;dbl&gt; \n$ Tenure                        &lt;chr&gt; \n$ `Completion Date`             &lt;chr&gt; \n$ `Purchaser Address Indicator` &lt;chr&gt; \n$ `Postal Code`                 &lt;chr&gt; \n$ `Postal District`             &lt;chr&gt; \n$ `Postal Sector`               &lt;chr&gt; \n$ `Planning Region`             &lt;chr&gt; \n$ `Planning Area`               &lt;chr&gt; \n\n\n\n\n\n\n\n\n\n\n\nData Analysis\n\n\n\nUsing glimpse() as a dipstick to run through our duplicate() checks, we concluded that the data is very sanitised with 0 duplicated transactions.\nHowever we noted that there is an unsuitable data type for the field ‘Sale Date’ which will result in difficulty for us not being able to do filtering later on.\n\n\n\n\nFiltering Q1 2024 data for Private properties\n\nCodeDate Format ChangeFiltering for only Q1 dataSample of Q1 Only Data\n\n\n\ncombined_transaction$`Sale Date` &lt;- dmy(combined_transaction$`Sale Date`)\n\n# Check the structure to ensure 'Sale Date' is now a Date object\nstr(combined_transaction)\n\nQ1_2024_Private &lt;- combined_transaction %&gt;%\n  filter(`Sale Date` &gt;= as.Date(\"2023-01-01\") & \n         `Sale Date` &lt;= as.Date(\"2024-03-31\"))\n\nhead(Q1_2024_Private)\n\n\n\n\ncombined_transaction$`Sale Date` &lt;- dmy(combined_transaction$`Sale Date`)\n\n# Check the structure to ensure 'Sale Date' is now a Date object\nstr(combined_transaction)\n\nspc_tbl_ [26,806 × 21] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:26806] \"THE REEF AT KING'S DOCK\" \"URBAN TREASURES\" \"NORTH GAIA\" \"NORTH GAIA\" ...\n $ Transacted Price ($)       : num [1:26806] 2317000 1823500 1421112 1258112 1280000 ...\n $ Area (SQFT)                : num [1:26806] 883 883 1076 1033 872 ...\n $ Unit Price ($ PSF)         : num [1:26806] 2625 2066 1320 1218 1468 ...\n $ Sale Date                  : Date[1:26806], format: \"2023-01-01\" \"2023-01-02\" ...\n $ Address                    : chr [1:26806] \"12 HARBOURFRONT AVENUE #05-32\" \"205 JALAN EUNOS #08-02\" \"29 YISHUN CLOSE #08-10\" \"45 YISHUN CLOSE #07-42\" ...\n $ Type of Sale               : chr [1:26806] \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr [1:26806] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num [1:26806] 82 82 100 96 81 ...\n $ Unit Price ($ PSM)         : num [1:26806] 28256 22238 14211 13105 15802 ...\n $ Nett Price($)              : chr [1:26806] \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr [1:26806] \"Condominium\" \"Condominium\" \"Executive Condominium\" \"Executive Condominium\" ...\n $ Number of Units            : num [1:26806] 1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr [1:26806] \"99 yrs from 12/01/2021\" \"Freehold\" \"99 yrs from 15/02/2021\" \"99 yrs from 15/02/2021\" ...\n $ Completion Date            : chr [1:26806] \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr [1:26806] \"HDB\" \"Private\" \"HDB\" \"HDB\" ...\n $ Postal Code                : chr [1:26806] \"097996\" \"419535\" \"269343\" \"269294\" ...\n $ Postal District            : chr [1:26806] \"04\" \"14\" \"27\" \"27\" ...\n $ Postal Sector              : chr [1:26806] \"09\" \"41\" \"26\" \"26\" ...\n $ Planning Region            : chr [1:26806] \"Central Region\" \"East Region\" \"North Region\" \"North Region\" ...\n $ Planning Area              : chr [1:26806] \"Bukit Merah\" \"Bedok\" \"Yishun\" \"Yishun\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `Project Name` = col_character(),\n  ..   `Transacted Price ($)` = col_number(),\n  ..   `Area (SQFT)` = col_number(),\n  ..   `Unit Price ($ PSF)` = col_number(),\n  ..   `Sale Date` = col_character(),\n  ..   Address = col_character(),\n  ..   `Type of Sale` = col_character(),\n  ..   `Type of Area` = col_character(),\n  ..   `Area (SQM)` = col_number(),\n  ..   `Unit Price ($ PSM)` = col_number(),\n  ..   `Nett Price($)` = col_character(),\n  ..   `Property Type` = col_character(),\n  ..   `Number of Units` = col_double(),\n  ..   Tenure = col_character(),\n  ..   `Completion Date` = col_character(),\n  ..   `Purchaser Address Indicator` = col_character(),\n  ..   `Postal Code` = col_character(),\n  ..   `Postal District` = col_character(),\n  ..   `Postal Sector` = col_character(),\n  ..   `Planning Region` = col_character(),\n  ..   `Planning Area` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\nQ1_2024_Private &lt;- combined_transaction %&gt;%\n  filter(`Sale Date` &gt;= as.Date(\"2023-01-01\") & \n         `Sale Date` &lt;= as.Date(\"2024-03-31\"))\n\n\n\n\nhead(Q1_2024_Private)\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 17 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;"
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#transaction-type-distribution-across-planning-regions-on-different-private-residential-types-in-1st-quarter-2024",
    "href": "take_home_ex/take_home_ex1.html#transaction-type-distribution-across-planning-regions-on-different-private-residential-types-in-1st-quarter-2024",
    "title": "Take Home Exercise 1",
    "section": "Transaction Type Distribution across Planning Regions on Different Private Residential Types in 1st Quarter 2024",
    "text": "Transaction Type Distribution across Planning Regions on Different Private Residential Types in 1st Quarter 2024\nFrom our initial peek into the available data attributes, there are a few key attributes which we believe is useful in revealing interesting observable trends such as Planning Region, PSF price and Property types.\nTo test this hypothesis, we will use a FacetGrid to show the significance each metric has on the total transactions.\n\nCode for FacetGridPlot for FacetGridDrilldown\n\n\n\nggplot(data=Q1_2024_Private, \n       aes(x = `Unit Price ($ PSF)`, \n           fill = `Type of Sale`)) +\n  geom_histogram(position = \"dodge\", binwidth = 100) +  # Adjust binwidth as needed\n  facet_grid(`Planning Region` ~ `Property Type`) +\n  labs(x = \"PSF Price\", y = \"Count\", title = \"Distribution of PSF Prices by Property Type, Region, and Transaction Type\") +\n  scale_fill_brewer(palette = \"Set1\") +  # Use a color palette that is distinct\n  theme_minimal() +\n  theme(legend.position = \"bottom\")  # Adjust legend position as needed\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=Q1_2024_Private, \n       aes(x = `Planning Region`, \n           fill = `Property Type`)) +\n  geom_bar(color = \"grey30\") +\n  labs(x = \"Region\", y = \"Transactions\", title = \"Sale of different property types in different Regions\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation from the Drilldown chart\n\n\n\nFrom the FacetGrid transaction volumes of Property Types segregated by the different regions, we observed that majority of the transactions happening in 2024 involves either Apartments or Condominiums in the Central Region.\nShifting gears into the types of sale, we can also observe that New Sale is very popular for Apartments in Central Region as well as Executive Condominiums in the West Region. This sentiment is also backed by Straits Times\nGiven that the graph has highlighted Region and Apartment Type has a high correlation in contributing to buyer’s interest, we have use a histogram to illustrate it in the drilldown chart."
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#average-transaction-price-by-sale-type-and-region",
    "href": "take_home_ex/take_home_ex1.html#average-transaction-price-by-sale-type-and-region",
    "title": "Take Home Exercise 1",
    "section": "Average Transaction Price by Sale Type and Region",
    "text": "Average Transaction Price by Sale Type and Region\nUsing Geospatial mapping later, we notice can now see clearly from a macro POV that the price distribution by PSF in Singapore.\nHowever, our literature research also shows that there are experts who claims that prices of properties are also affected by their age and sale type.\n\nlibrary(ggthemes)\n\nq1_psf &lt;- Q1_2024_Private %&gt;%\n  group_by(`Type of Sale` , `Planning Region`) %&gt;%\n  summarize(`Average PSF` = mean(`Unit Price ($ PSF)`), .groups = \"drop\")\nq1_psf\n\n# A tibble: 15 × 3\n   `Type of Sale` `Planning Region` `Average PSF`\n   &lt;chr&gt;          &lt;chr&gt;                     &lt;dbl&gt;\n 1 New Sale       Central Region            2682.\n 2 New Sale       East Region               1793.\n 3 New Sale       North East Region         2161.\n 4 New Sale       North Region              1319.\n 5 New Sale       West Region               1911.\n 6 Resale         Central Region            1895.\n 7 Resale         East Region               1369.\n 8 Resale         North East Region         1440.\n 9 Resale         North Region              1213.\n10 Resale         West Region               1376.\n11 Sub Sale       Central Region            2154.\n12 Sub Sale       East Region               1659.\n13 Sub Sale       North East Region         1729.\n14 Sub Sale       North Region              1485 \n15 Sub Sale       West Region               1995.\n\n# Calculate overall mean of 'Average PSF'\noverall_mean &lt;- mean(q1_psf$`Average PSF`)\n\nggplot(q1_psf, aes(x = `Planning Region`, y = `Average PSF`, fill = `Type of Sale`)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  geom_hline(yintercept = overall_mean, linetype = \"dashed\", color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Average PSF by Region and Type of Sale\",\n       x = \"Planning Region\",\n       y = \"Average PSF\",\n       fill = \"Type of Sale\") +\n  scale_fill_manual(values = c(\"New Sale\" = \"blue\", \"Resale\" = \"red\", \"Sub Sale\" = \"orange\")) +   annotate(\"text\", x = Inf, y = overall_mean, label = paste(\"Average PSF:\", round(overall_mean, 2)), \n           vjust = -0.5, hjust = 1.1, color = \"black\", size = 3.5)\n\n\n\n\n\n\n\n\n\n\nObservation of PSF prices for all transactions\n\n\n\nObserving the bar chart, we can note that the Central Region exhibits the highest Average PSF for new sales, which is significantly above the overall average. In contrast, the North Region presents the lowest Average PSF figures for both new sales and resales.\nLastly, the chart also shows a clear trend where new sales consistently have higher Average PSF values compared to resales across all regions. The additional category of ‘Sub Sale’—present only for the East Region—falls below the overall mean. The overall mean PSF, marked by the dashed line, lies just below the Average PSF for resales in the Central Region, suggesting a higher concentration of sales with above-average prices in that region."
  },
  {
    "objectID": "take_home_ex/take_home_ex1.html#additional-bonus-average-transaction-price-by-region",
    "href": "take_home_ex/take_home_ex1.html#additional-bonus-average-transaction-price-by-region",
    "title": "Take Home Exercise 1",
    "section": "[Additional Bonus] Average Transaction Price by Region",
    "text": "[Additional Bonus] Average Transaction Price by Region\nTo visualise the variation in average property prices across different regions in Singapore, we will use a choropleth map and shade each region according to its average property price which makes pricing differences immediately obvious.\nTo create the map, we will need the sub-zone boundary of URA Master Plan 2019 dataset as well as our own Q1_2024_Private dataset which we created earlier on.\nThe tools required are :\n\npacman::p_load(tmap,sf, httr, dplyr, future, furrr)\n\n\n\n\n\n\n\n\nComponents\nDescription\n\n\n\n\ntmap\nThe syntax for creating plots is similar to that of ggplot2, but tailored to maps\n\n\nsf\nSupport for simple features, a standardized way to encode spatial vector data\n\n\nhttr2\nCreate and submit HTTP requests and work with the HTTP responses\n\n\nfuture\nFor sequential and parallel processing of R expression. This will be useful for expediting processing time later on.\n\n\n\n\nStep 1\nThe first step is to utilise Singapore’s OneMap service to map each postal code to their corresponding Longtidue and Latitude.\n\nCreate a new cache layer to store found postal codeCreate Base API call with a catch clauseStore found data in ‘result’ dataframe\n\n\n\ncache &lt;- new.env()\nplan(multisession)\n\n\n\n\nfetch_geocode_data &lt;- function(postcode)\n  # Check cache first\n  if (exists(postcode, envir = cache)) {\n    return(get(postcode, envir = cache))\n  }\n  \n  # API parameters\n  url &lt;- \"https://www.onemap.gov.sg/api/common/elastic/search\"\n  query_params &lt;- list(searchVal = postcode, returnGeom = 'Y', getAddrDetails = 'Y', pageNum = '1')\n\n  # API call with error handling\n  response &lt;- tryCatch({\n    GET(url, query = query_params)\n  }, error = function(e) {\n    message(\"Error fetching data for postcode \", postcode, \": \", e$message)\n    return(NULL)\n  })\n\n  # Check if the API call was successful\n  if (is.null(response) || http_error(response)) {\n    return(data.frame(postcode = postcode, lat = NA, lon = NA))\n  }\n\n  # Parse response\n  content_data &lt;- content(response, type = \"application/json\")\n\n  # Store in cache and return results\n  if (content_data$found &gt; 0) {\n    lat &lt;- content_data$results[[1]]$LATITUDE\n    lon &lt;- content_data$results[[1]]$LONGITUDE\n    result &lt;- data.frame(postcode = postcode, lat = lat, lon = lon)\n  } else {\n    result &lt;- data.frame(postcode = postcode, lat = NA, lon = NA)\n  }\n\n\n\n\n  assign(postcode, result, envir = cache)\n  return(result)\n\n##Output\n\ncache &lt;- new.env()\nplan(multisession)\n\nfetch_geocode_data &lt;- function(postcode) {\n  # Check cache first\n  if (exists(postcode, envir = cache)) {\n    return(get(postcode, envir = cache))\n  }\n  \n  # API parameters\n  url &lt;- \"https://www.onemap.gov.sg/api/common/elastic/search\"\n  query_params &lt;- list(searchVal = postcode, returnGeom = 'Y', getAddrDetails = 'Y', pageNum = '1')\n\n  # API call with error handling\n  response &lt;- tryCatch({\n    GET(url, query = query_params)\n  }, error = function(e) {\n    message(\"Error fetching data for postcode \", postcode, \": \", e$message)\n    return(NULL)\n  })\n\n  # Check if the API call was successful\n  if (is.null(response) || http_error(response)) {\n    return(data.frame(postcode = postcode, lat = NA, lon = NA))\n  }\n\n  # Parse response\n  content_data &lt;- content(response, type = \"application/json\")\n\n  # Store in cache and return results\n  if (content_data$found &gt; 0) {\n    lat &lt;- content_data$results[[1]]$LATITUDE\n    lon &lt;- content_data$results[[1]]$LONGITUDE\n    result &lt;- data.frame(postcode = postcode, lat = lat, lon = lon)\n  } else {\n    result &lt;- data.frame(postcode = postcode, lat = NA, lon = NA)\n  }\n\n  assign(postcode, result, envir = cache)\n  return(result)\n}\n\n\n\n\n\n\nStep 2\nWe will now match Transaction (Q1_2024_Private) Tibble Dataframe’s unique postal code to our list of postal code extracted from OneMap.\n\n# Search 'Q1_2024_Private' dataframe for 'Postal Code' column\ndata_pc &lt;- unique(Q1_2024_Private$`Postal Code`)\n\n# Use futures for asynchronous processing\nresults &lt;- future_map(data_pc, fetch_geocode_data)\ncombined_results &lt;- bind_rows(results)\n\n# Combine results and filter out unsuccessful ones\nsuccessful_results &lt;- combined_results %&gt;%\n  filter(!is.na(lat) & !is.na(lon))\n\n# Write results to a CSV file\nwrite.csv(successful_results, file = \"data/PostalCodeList.csv\", row.names = FALSE)\n\n\nQ1_2024_Private_with_Coordinates &lt;- Q1_2024_Private %&gt;%\n  left_join(successful_results, by = c(\"Postal Code\" = \"postcode\"))\n\n\n\nStep 3 Importing Geospatial Data\nLoad Map into MPSZ\n\n# Instantiate the map from MPSZ 2019\nmpsz &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS608-VAA/take_home_ex/data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n# Remove rows where latitude or longitude is NA\nQ1_2024_Private_with_Coordinates &lt;- Q1_2024_Private_with_Coordinates %&gt;%\n  filter(!is.na(lat) & !is.na(lon))\n\nq1_2024_sf &lt;- st_as_sf(Q1_2024_Private_with_Coordinates ,\n                       coords = c(\"lon\", \"lat\"),\n                       crs =4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\nStep 4 - Extracting study data (Average Transacted Price)\nWe will filter out the column data - Transacted Price, PSF & Planning Area which is required for a drill-down analysis on consumer pattern.\n\nq1_avg_txn &lt;- Q1_2024_Private_with_Coordinates %&gt;%\n    group_by(`Planning Area`) %&gt;%\n    summarise(Avg_Transacted_Price = mean(`Transacted Price ($)`, na.rm = TRUE))\nq1_avg_txn &lt;- q1_avg_txn %&gt;%\n    mutate(`Planning Area` = toupper(`Planning Area`))\nq1_avg_txn &lt;- st_drop_geometry(q1_avg_txn)\n\n\nq1_avg_psf &lt;- Q1_2024_Private_with_Coordinates %&gt;%\n    group_by(`Planning Area`) %&gt;%\n    summarise(Avg_Transacted_PSF = mean(`Unit Price ($ PSF)`, na.rm = TRUE))\nq1_avg_psf &lt;- q1_avg_psf %&gt;%\n    mutate(`Planning Area` = toupper(`Planning Area`))\nq1_avg_psf &lt;- st_drop_geometry(q1_avg_psf)\n\n\n\nStep 5 - Geospatial Data Wrangling\n\nAverage Transacted Price ( Planning Region )Average PSF ( Planning Region )\n\n\n\nmpsz_avg_txn_px &lt;- mpsz %&gt;%\n    left_join(\n        q1_avg_txn,\n        by = c(\"PLN_AREA_N\" = \"Planning Area\")\n    ) %&gt;% drop_na()\n\ntmap_mode(\"view\")\n\nmap2 &lt;- tm_shape(mpsz_avg_txn_px) +\n    tm_polygons(col = \"Avg_Transacted_Price\", \n                palette = \"YlOrRd\",\n                alpha = 0.3,\n                style = \"quantile\",\n                n = 7) +\n    tmap_options(check.and.fix = TRUE) +\n  tm_view(set.zoom.limits = c(11,14))\n\nmap2\n\n\n\n\n\n\n\n\n\nmpsz_avg_psf &lt;- mpsz %&gt;%\n    left_join(\n        q1_avg_psf,\n        by = c(\"PLN_AREA_N\" = \"Planning Area\")\n    ) %&gt;% drop_na()\n\ntmap_mode(\"view\")\n\nmap3 &lt;- tm_shape(mpsz_avg_psf) +\n    tm_polygons(col = \"Avg_Transacted_PSF\",\n                palette = \"YlOrRd\", \n                alpha = 0.3,\n                style = \"quantile\",\n                n = 7) +\n    tmap_options(check.and.fix = TRUE) +\n  tm_view(set.zoom.limits = c(11,14))\n\nmap3"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html",
    "href": "In_class_ex/Hands-on_Ex06.html",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nThe downloaded binary packages are in\n    /var/folders/0t/cj2bqwc917g2wsrl5n6f34180000gn/T//RtmpFuI3PK/downloaded_packages\n\nThe downloaded binary packages are in\n    /var/folders/0t/cj2bqwc917g2wsrl5n6f34180000gn/T//RtmpFuI3PK/downloaded_packages\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\nlayout argument is used to define the layout to be used\n\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\nmutate() of dplyr is used to perform the computation. the algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#overview",
    "href": "In_class_ex/Hands-on_Ex06.html#overview",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#getting-started",
    "href": "In_class_ex/Hands-on_Ex06.html#getting-started",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nThe downloaded binary packages are in\n    /var/folders/0t/cj2bqwc917g2wsrl5n6f34180000gn/T//RtmpFuI3PK/downloaded_packages\n\nThe downloaded binary packages are in\n    /var/folders/0t/cj2bqwc917g2wsrl5n6f34180000gn/T//RtmpFuI3PK/downloaded_packages"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#the-data",
    "href": "In_class_ex/Hands-on_Ex06.html#the-data",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "In_class_ex/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "In_class_ex/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\nlayout argument is used to define the layout to be used\n\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "In_class_ex/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "In_class_ex/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\nmutate() of dplyr is used to perform the computation. the algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "In_class_ex/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands On Exercise 6",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html",
    "href": "In_class_ex/hands-on_ex4.html",
    "title": "Hands-On Exercise 4",
    "section": "",
    "text": "#Learning Objectives\nIn the earlier chapters we have shared dealt with some of the popular statistical graphics methods for visualising distribution such as histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2.\nIn this handson, we are going to use new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\nFor the purpose of this exercise, the following R packages will be used, they are:"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#loading-the-packages",
    "href": "In_class_ex/hands-on_ex4.html#loading-the-packages",
    "title": "Hands-On Exercise 4",
    "section": "Loading the packages",
    "text": "Loading the packages\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\nImporting the data\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#visualising-distribution-with-ridgeline-plot",
    "href": "In_class_ex/hands-on_ex4.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-On Exercise 4",
    "section": "Visualising Distribution with Ridgeline Plot",
    "text": "Visualising Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups of categorical indicators.\nDistribution in Ridgeline plot can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#plotting-ridgeline-graph-with-ggridges-method",
    "href": "In_class_ex/hands-on_ex4.html#plotting-ridgeline-graph-with-ggridges-method",
    "title": "Hands-On Exercise 4",
    "section": "Plotting ridgeline graph with ggridges method",
    "text": "Plotting ridgeline graph with ggridges method\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#having-various-colors-on-x-axis-in-ridgelines",
    "href": "In_class_ex/hands-on_ex4.html#having-various-colors-on-x-axis-in-ridgelines",
    "title": "Hands-On Exercise 4",
    "section": "Having various colors on X axis in ridgelines",
    "text": "Having various colors on X axis in ridgelines\nThis effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThis method does not allow for transaprency given it’s limitations"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#mapping-probabilities-using-color",
    "href": "In_class_ex/hands-on_ex4.html#mapping-probabilities-using-color",
    "title": "Hands-On Exercise 4",
    "section": "Mapping probabilities using color",
    "text": "Mapping probabilities using color\nggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nThis is done by mapping the probabilities calculated using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe empirical cumulative distribution function (ECDF) provides an alternative visualisation of distribution. Compared to other visualisations that rely on density (like geom_histogram()), the ECDF doesn’t require any tuning parameters and handles both continuous and categorical variables. The downside is that it requires more training to accurately interpret, and the underlying visual tasks are somewhat more challenging.\nQuantile–quantile (q-q) plots are a useful visualization when we want to determine to what extent the observed data points do or do not follow a given distribution. Just like ecdfs, q-q plots are also based on ranking the data and visualizing the relationship between ranks and actual values.\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges()."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#ridgeline-plots-with-quantile-lines",
    "href": "In_class_ex/hands-on_ex4.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-On Exercise 4",
    "section": "Ridgeline plots with quantile lines",
    "text": "Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\nSpecifying quantiles by cut points\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4.html#visualising-distribution-with-raincloud-plot",
    "href": "In_class_ex/hands-on_ex4.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-On Exercise 4",
    "section": "Visualising distribution with Raincloud plot",
    "text": "Visualising distribution with Raincloud plot\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\n\nPlotting a halfeye graph\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\nAdding the boxplot with geom_boxplot()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\nAdding the Dot Plots with stat_dots()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\nAdding themes with theme_economist()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html",
    "href": "In_class_ex/hands-on_ex3.html",
    "title": "Hands On Exercise 3",
    "section": "",
    "text": "Create interactive data visualisation by using functions provided by ggiraph and plotlyr packages"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#installing-the-required-libraries",
    "href": "In_class_ex/hands-on_ex3.html#installing-the-required-libraries",
    "title": "Hands On Exercise 3",
    "section": "Installing the required libraries",
    "text": "Installing the required libraries\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#importing-the-data",
    "href": "In_class_ex/hands-on_ex3.html#importing-the-data",
    "title": "Hands On Exercise 3",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nTo create an interactive version of ggplot2 geom (i.e. [geom_dotplot_interactive()] we first need to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#displaying-multiple-information-on-tooltip",
    "href": "In_class_ex/hands-on_ex3.html#displaying-multiple-information-on-tooltip",
    "title": "Hands On Exercise 3",
    "section": "Displaying multiple information on tooltip",
    "text": "Displaying multiple information on tooltip\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7. By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#customising-tooltop-style",
    "href": "In_class_ex/hands-on_ex3.html#customising-tooltop-style",
    "title": "Hands On Exercise 3",
    "section": "Customising Tooltop style",
    "text": "Customising Tooltop style\nCode chunk below uses [opts_tooltip()] of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#displaying-statistics-on-tooltip",
    "href": "In_class_ex/hands-on_ex3.html#displaying-statistics-on-tooltip",
    "title": "Hands On Exercise 3",
    "section": "Displaying statistics on tooltip",
    "text": "Displaying statistics on tooltip\nTHis is an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#hover-effect-with-data-id.-aesthetic",
    "href": "In_class_ex/hands-on_ex3.html#hover-effect-with-data-id.-aesthetic",
    "title": "Hands On Exercise 3",
    "section": "Hover effect with data id. aesthetic",
    "text": "Hover effect with data id. aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#styling-hover-effect",
    "href": "In_class_ex/hands-on_ex3.html#styling-hover-effect",
    "title": "Hands On Exercise 3",
    "section": "Styling hover effect",
    "text": "Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#plot-1-combining-tooltip-and-hover-effect",
    "href": "In_class_ex/hands-on_ex3.html#plot-1-combining-tooltip-and-hover-effect",
    "title": "Hands On Exercise 3",
    "section": "Plot 1: Combining tooltip and hover effect",
    "text": "Plot 1: Combining tooltip and hover effect\nThe tooltip and hover effects are combined in the interactive statistical graph in the code chunk below.\nElements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#click-effect-with-onclick",
    "href": "In_class_ex/hands-on_ex3.html#click-effect-with-onclick",
    "title": "Hands On Exercise 3",
    "section": "Click effect with onclick",
    "text": "Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web. Web document link with a data object will be displayed on the web browser upon mouse click.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nClick actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#coordinated-multiple-views-with-ggiraph",
    "href": "In_class_ex/hands-on_ex3.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands On Exercise 3",
    "section": "Coordinated Multiple Views with ggiraph",
    "text": "Coordinated Multiple Views with ggiraph\nWhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#there-are-two-ways-to-create-interactive-graph-by-using-plotly-they-are",
    "href": "In_class_ex/hands-on_ex3.html#there-are-two-ways-to-create-interactive-graph-by-using-plotly-they-are",
    "title": "Hands On Exercise 3",
    "section": "There are two ways to create interactive graph by using plotly, they are:",
    "text": "There are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "In_class_ex/hands-on_ex3.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Hands On Exercise 3",
    "section": "Creating an interactive scatter plot: plot_ly() method",
    "text": "Creating an interactive scatter plot: plot_ly() method\nA basic interactive plot created by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#working-with-visual-variable-plot_ly-method",
    "href": "In_class_ex/hands-on_ex3.html#working-with-visual-variable-plot_ly-method",
    "title": "Hands On Exercise 3",
    "section": "Working with visual variable: plot_ly() method",
    "text": "Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "In_class_ex/hands-on_ex3.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Hands On Exercise 3",
    "section": "Creating an interactive scatter plot: ggplotly() method",
    "text": "Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly()."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#plot",
    "href": "In_class_ex/hands-on_ex3.html#plot",
    "title": "Hands On Exercise 3",
    "section": "Plot",
    "text": "Plot\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe only extra line you need to include in the code chunk is ggplotly()."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#interactive-data-visualisation---crosstalk-methods",
    "href": "In_class_ex/hands-on_ex3.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands On Exercise 3",
    "section": "Interactive Data Visualisation - crosstalk methods",
    "text": "Interactive Data Visualisation - crosstalk methods\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#linked-brushing-crosstalk-method",
    "href": "In_class_ex/hands-on_ex3.html#linked-brushing-crosstalk-method",
    "title": "Hands On Exercise 3",
    "section": "Linked brushing: crosstalk method",
    "text": "Linked brushing: crosstalk method\nCode chunk below is used to implement coordinated brushing."
  },
  {
    "objectID": "In_class_ex/hands-on_ex3.html#plot-1",
    "href": "In_class_ex/hands-on_ex3.html#plot-1",
    "title": "Hands On Exercise 3",
    "section": "Plot",
    "text": "Plot\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "In_class_ex/In-class_ex4.html",
    "href": "In_class_ex/In-class_ex4.html",
    "title": "In class exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)\nexam &lt;- read_csv(\"data/Exam_data.csv\")\nset.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"robust\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey 50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English scores\"\n)\n##get the numbers\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 10\n  statistic p.value n.obs method                                 effectsize  \n      &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;                                  &lt;chr&gt;       \n1      11.1       0   322 Bootstrap-t method for one-sample test Trimmed mean\n  estimate conf.level conf.low conf.high expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;list&gt;    \n1     69.2       0.95     67.8      70.6 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols=ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\"\n  ) %&gt;%\n  filter(CLASS == \"3A\")\nggwithinstats (\n  data = filter(exam_long, \n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90,\n)"
  },
  {
    "objectID": "In_class_ex/In-class_ex4.html#toyota-sales-exercise",
    "href": "In_class_ex/In-class_ex4.html#toyota-sales-exercise",
    "title": "In class exercise 4",
    "section": "Toyota sales exercise",
    "text": "Toyota sales exercise\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\nMultiple Regressions using lm()\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nChecking and plotting multicollinearity\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\nChecking for nomality assumption\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\nModel diagnostic: Complete check\n\ncheck_model(model1)"
  },
  {
    "objectID": "In_class_ex/In-class_ex4.html#visualising-regression-param",
    "href": "In_class_ex/In-class_ex4.html#visualising-regression-param",
    "title": "In class exercise 4",
    "section": "Visualising Regression param",
    "text": "Visualising Regression param\n\nplot(parameters(model1))\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html",
    "href": "In_class_ex/hands-on_ex3_2.html",
    "title": "hands-on_ex3_2",
    "section": "",
    "text": "#Objectives - Create animated data visualisation by using gganimate and plotly r packages - Reshape data by using tidyr package - Process, wrangle and transform data by using dplyr package"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#installing-and-loading-the-required-libraries",
    "href": "In_class_ex/hands-on_ex3_2.html#installing-and-loading-the-required-libraries",
    "title": "hands-on_ex3_2",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#importing-the-data",
    "href": "In_class_ex/hands-on_ex3_2.html#importing-the-data",
    "title": "hands-on_ex3_2",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nThe code chunk below imports GlobalPopulation.xlsx into R environment by using read_xls() function of readr package.\nreadr is a pacakge within tidyverse.\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#building-a-static-population-bubble-plot",
    "href": "In_class_ex/hands-on_ex3_2.html#building-a-static-population-bubble-plot",
    "title": "hands-on_ex3_2",
    "section": "Building a static population bubble plot",
    "text": "Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#building-the-animated-bubble-plot",
    "href": "In_class_ex/hands-on_ex3_2.html#building-the-animated-bubble-plot",
    "title": "hands-on_ex3_2",
    "section": "Building the animated bubble plot",
    "text": "Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics.\n\nThe default is linear.\nOther methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#building-an-animated-bubble-plot-ggplotly-method",
    "href": "In_class_ex/hands-on_ex3_2.html#building-an-animated-bubble-plot-ggplotly-method",
    "title": "hands-on_ex3_2",
    "section": "Building an animated bubble plot: ggplotly() method",
    "text": "Building an animated bubble plot: ggplotly() method\nCreate an animated bubble plot by using ggplotly() method.\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\nAlthough show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex3_2.html#building-an-animated-bubble-plot-plot_ly-method",
    "href": "In_class_ex/hands-on_ex3_2.html#building-an-animated-bubble-plot-plot_ly-method",
    "title": "hands-on_ex3_2",
    "section": "Building an animated bubble plot: plot_ly() method",
    "text": "Building an animated bubble plot: plot_ly() method\nCreate an animated bubble plot by using plot_ly() method.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "In_class_ex/In_class_ex6.html",
    "href": "In_class_ex/In_class_ex6.html",
    "title": "In-class_ex6",
    "section": "",
    "text": "MC1 Model Answer\n\npacman::p_load(stringi, stringr, rvest, corporaexplorer, tidyverse)\n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n# Collapsing into one string.\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html",
    "href": "In_class_ex/hands-on_ex4_3.html",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "",
    "text": "To learn about Funnel plots which is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#importing-the-dat",
    "href": "In_class_ex/hands-on_ex4_3.html#importing-the-dat",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Importing the dat",
    "text": "Importing the dat\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#basic-plot-with-funnelplotr",
    "href": "In_class_ex/hands-on_ex4_3.html#basic-plot-with-funnelplotr",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Basic plot with FunnelPlotR",
    "text": "Basic plot with FunnelPlotR\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Positive`,\n  denominator = `Death`,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#funnelplotr-methods-makeover-1",
    "href": "In_class_ex/hands-on_ex4_3.html#funnelplotr-methods-makeover-1",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "FunnelPlotR methods: Makeover 1",
    "text": "FunnelPlotR methods: Makeover 1\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Death`,\n  denominator = `Positive`,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  x_range = c(0, 6500),  #&lt;&lt;\n  y_range = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#funnelplotr-method-makeover-2",
    "href": "In_class_ex/hands-on_ex4_3.html#funnelplotr-method-makeover-2",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "FunnelPlotR method: Makeover 2",
    "text": "FunnelPlotR method: Makeover 2\n\nfunnel_plot(\n  .data = covid19,\n  numerator = `Death`,\n  denominator = `Positive`,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)    \n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#funnel-plot-for-fair-visual-comparison-ggplot2-method",
    "href": "In_class_ex/hands-on_ex4_3.html#funnel-plot-for-fair-visual-comparison-ggplot2-method",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 method",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 method\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "href": "In_class_ex/hands-on_ex4_3.html#calculate-lower-and-upper-limits-for-95-and-99.9-ci",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Calculate lower and upper limits for 95% and 99.9% CI",
    "text": "Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#plotting-a-static-funnel-plot",
    "href": "In_class_ex/hands-on_ex4_3.html#plotting-a-static-funnel-plot",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Plotting a static funnel plot",
    "text": "Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_3.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "In_class_ex/hands-on_ex4_3.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands on Exercise 4 - Part 3",
    "section": "Interactive Funnel Plot: plotly + ggplot2",
    "text": "Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "In_class_ex/In-class_ex5_2.html",
    "href": "In_class_ex/In-class_ex5_2.html",
    "title": "In-class_ex5_2",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, quanteda, tidytext, jsonlite, DT)\nmc1_data &lt;- fromJSON(\"data/mc1.json\")"
  },
  {
    "objectID": "In_class_ex/In-class_ex5_2.html#to-view-the-dataframe",
    "href": "In_class_ex/In-class_ex5_2.html#to-view-the-dataframe",
    "title": "In-class_ex5_2",
    "section": "To view the dataframe",
    "text": "To view the dataframe\n\nview(mc1_data[[\"nodes\"]])\nview(mc1_data[[\"links\"]])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "This is a YT’s Quadro website for Year 2024 TSKAM’s Visual Analytics Course.\nBelow is me 2024 January\n\n& Now this is me after Aug 2024:"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html",
    "href": "In_class_ex/hands-on_ex4_2.html",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nThe code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nTip\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\ncode chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\nPlot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nPlotting the interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggdist2 is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nUsing stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nThis function however comes with many arguments and some interesting ones are as follows:\n.width = 0.95 .point = median .interval = qi (quantile interval, qi; highest-density interval, hdi; or highest-density continuous interval, hdci) .inherit.aes = If FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nStep 1:\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nStep 2: Launch the app in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#loading-the-packages",
    "href": "In_class_ex/hands-on_ex4_2.html#loading-the-packages",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "pacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#importing-data",
    "href": "In_class_ex/hands-on_ex4_2.html#importing-data",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "exam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#visualizing-the-uncertainty-of-point-estimates-using-ggplot2-methods",
    "href": "In_class_ex/hands-on_ex4_2.html#visualizing-the-uncertainty-of-point-estimates-using-ggplot2-methods",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nThe code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nTip\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\ncode chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\nPlot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#plotting-confidence-interval-of-point-estimates",
    "href": "In_class_ex/hands-on_ex4_2.html#plotting-confidence-interval-of-point-estimates",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "Instead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "In_class_ex/hands-on_ex4_2.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "Plotting the interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "In_class_ex/hands-on_ex4_2.html#visualising-uncertainty-with-ggdist2-packages",
    "href": "In_class_ex/hands-on_ex4_2.html#visualising-uncertainty-with-ggdist2-packages",
    "title": "Hands On Exercise 4 - Visualise Uncertainty",
    "section": "",
    "text": "ggdist2 is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nUsing stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nThis function however comes with many arguments and some interesting ones are as follows:\n.width = 0.95 .point = median .interval = qi (quantile interval, qi; highest-density interval, hdi; or highest-density continuous interval, hdci) .inherit.aes = If FALSE, overrides the default aesthetics, rather than combining with them. This is most useful for helper functions that define both data and aesthetics and shouldn’t inherit behaviour from the default plot specification, e.g. borders().\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\nStep 1:\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nStep 2: Launch the app in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html",
    "href": "In_class_ex/In-class_Ex02.html",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggplot2, ggdist, ggthemes, colorspace, ggridges)\n\n\n\n\n\nexam_df &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#setting-up-the-environment",
    "href": "In_class_ex/In-class_Ex02.html#setting-up-the-environment",
    "title": "In-class_Ex02 Demo",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggplot2, ggdist, ggthemes, colorspace, ggridges)\n\n\n\n\n\nexam_df &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#visualising-distribution",
    "href": "In_class_ex/In-class_Ex02.html#visualising-distribution",
    "title": "In-class_Ex02 Demo",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution\n\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\nggplot(exam_df,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6\n  )+\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_eng,\n                sd = std_eng),\n    col = \"grey30\",\n    size = .8) +\n  geom_vline(\n    aes(xintercept = mean_eng),\n    \n  )"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#probability-density-plot",
    "href": "In_class_ex/In-class_Ex02.html#probability-density-plot",
    "title": "In-class_Ex02 Demo",
    "section": "Probability Density Plot",
    "text": "Probability Density Plot\nAppropriate method for representing continuous values"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#density-plot-with-summary-statistics",
    "href": "In_class_ex/In-class_Ex02.html#density-plot-with-summary-statistics",
    "title": "In-class_Ex02 Demo",
    "section": "Density Plot with Summary Statistics",
    "text": "Density Plot with Summary Statistics\nThe code chunk below includes a probability density plot (violet) and normal distribution plot (gray). The mean (green) and median (blue) of the data is also plotted.\n\nmedian_eng &lt;- median(exam_df$ENGLISH)\nmean_eng &lt;- mean(exam_df$ENGLISH)\nstd_eng &lt;- sd(exam_df$ENGLISH)\n\n\n# Probability Density Plot\nggplot(data=exam_df, aes(x = ENGLISH)) +\n  geom_density(color=\"violet\", \n               adjust = .65,\n               alpha = .1) +\n  stat_function( # Normal Distribution Plot\n    fun = dnorm,\n    args = list(mean = mean_eng, sd = std_eng),\n    col = \"gray\",\n    linewidth = .8) +\n  geom_vline( # Mean line\n    aes(xintercept = mean_eng),\n    colour = \"darkgreen\",\n    linewidth = .6,\n    linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = mean_eng -8,\n           y = .04,\n           label = paste0(\"Mean: \",\n                          round((mean_eng),2)),\n           colour=\"darkgreen\") +\n  geom_vline( # Median Line\n    aes(xintercept = median_eng),\n    colour = \"navy\",\n    linewidth = .6,\n    linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = median_eng +8,\n           y = .04,\n           label = paste0(\"Median: \",\n                          round((mean_eng),2)),\n           colour=\"navy\") +\n  ggtitle(\"Density Plot with Summary Statistics of English Scores\")"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#ridgeline-plot",
    "href": "In_class_ex/In-class_Ex02.html#ridgeline-plot",
    "title": "In-class_Ex02 Demo",
    "section": "Ridgeline Plot",
    "text": "Ridgeline Plot\nRidgeline plot (i.e. Joyplot) reveals the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale with slightoverlaps"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#varying-fill-colours-along-the-x-axis",
    "href": "In_class_ex/In-class_Ex02.html#varying-fill-colours-along-the-x-axis",
    "title": "In-class_Ex02 Demo",
    "section": "Varying Fill Colours along the X-axis",
    "text": "Varying Fill Colours along the X-axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis.\n\nggplot(exam_df, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [°C]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English Grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#mapping-probabilities-directly-onto-colour",
    "href": "In_class_ex/In-class_Ex02.html#mapping-probabilities-directly-onto-colour",
    "title": "In-class_Ex02 Demo",
    "section": "Mapping Probabilities directly onto colour",
    "text": "Mapping Probabilities directly onto colour\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score."
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#ridgeline-plots-with-quantile-lines",
    "href": "In_class_ex/In-class_Ex02.html#ridgeline-plots-with-quantile-lines",
    "title": "In-class_Ex02 Demo",
    "section": "Ridgeline Plots with Quantile Lines",
    "text": "Ridgeline Plots with Quantile Lines\nRidgeline plots can be coloured by quantile using geom_density_ridges_gradient(), via the calculated stat(quantile) \n\n\n\n\n\nQuantiles can also be specified by cut points e.g. 2.5% and 97.5% tails to colour the ridgeline plot."
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#plotting-a-half-eye-graph",
    "href": "In_class_ex/In-class_Ex02.html#plotting-a-half-eye-graph",
    "title": "In-class_Ex02 Demo",
    "section": "Plotting a Half Eye graph",
    "text": "Plotting a Half Eye graph\nPlot a Half-Eye graph by using stat_halfeye() of ggdist package, producing a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRemove the slab interval by setting .width = 0 and point_colour = NA."
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#adding-the-boxplot",
    "href": "In_class_ex/In-class_Ex02.html#adding-the-boxplot",
    "title": "In-class_Ex02 Demo",
    "section": "Adding the boxplot",
    "text": "Adding the boxplot\nThe second geometry layer i.e. a narrow boxplot is produced using geom_boxplot() of ggplot2 This produces a narrow boxplot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#adding-the-dot-plots",
    "href": "In_class_ex/In-class_Ex02.html#adding-the-dot-plots",
    "title": "In-class_Ex02 Demo",
    "section": "Adding the Dot Plots",
    "text": "Adding the Dot Plots\nThe third geometry layer is added using stat_dots() of ggdist package. This produces a half-dotplot, similar to a histogram that indicates the number of samples (number of dots) in each bin. Use side = “left” to specify the dot plots on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "In_class_ex/In-class_Ex02.html#finishing-touch",
    "href": "In_class_ex/In-class_Ex02.html#finishing-touch",
    "title": "In-class_Ex02 Demo",
    "section": "Finishing touch",
    "text": "Finishing touch\n coord_flip() of ggplot2 package is used to flip the raincloud chart horizontally to give it the raincloud appearance. theme_economist() of ggthemes package is also used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "In_class_ex/In-class_Ex01.html",
    "href": "In_class_ex/In-class_Ex01.html",
    "title": "In-class_ex1",
    "section": "",
    "text": "In the code chunk below, [p_load()] of pacman pkg is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis, aes(x = `Unit Price ($ psm)`)) + geom_histogram()"
  },
  {
    "objectID": "In_class_ex/In-class_Ex01.html#loading-r-packages",
    "href": "In_class_ex/In-class_Ex01.html#loading-r-packages",
    "title": "In-class_ex1",
    "section": "",
    "text": "In the code chunk below, [p_load()] of pacman pkg is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis, aes(x = `Unit Price ($ psm)`)) + geom_histogram()"
  },
  {
    "objectID": "In_class_ex/In-class_ex5.html",
    "href": "In_class_ex/In-class_ex5.html",
    "title": "In-class_ex5",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, quanteda, tidytext, jsonlite, DT)\n\n\nprint(paste0(\"Checking directory: \", \"/data/articles/*\"))\n\n[1] \"Checking directory: /data/articles/*\"\n\nprint(list.files(\"/data/articles/*\"))\n\ncharacter(0)\n\n\n\ntext_data = readtext(\"data/articles/*\")\nglimpse(text_data)\n\nRows: 338\nColumns: 2\n$ doc_id &lt;chr&gt; \"Alvarez PLC__0__0__Haacklee Herald.txt\", \"Alvarez PLC__0__0__L…\n$ text   &lt;chr&gt; \"Marine Sanctuary Aid Boosts Alvarez PLC's Sustainable Fishing …\n\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3261 documents and 0 docvars.\n# A data frame: 3,261 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,255 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\",\"Y\"),\n                       too_few = \"align_end\")"
  },
  {
    "objectID": "In_class_ex/Inclass5.html",
    "href": "In_class_ex/Inclass5.html",
    "title": "test",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, quanteda, tidytext, jsonlite, DT)\n\n\nprint(paste0(\"Checking directory: \", \"/data/articles/*\"))\n\n[1] \"Checking directory: /data/articles/*\"\n\nprint(list.files(\"/data/articles/*\"))\n\ncharacter(0)\n\n\n\ntext_data = readtext(\"data/articles/*\")\nglimpse(text_data)\n\nRows: 338\nColumns: 2\n$ doc_id &lt;chr&gt; \"Alvarez PLC__0__0__Haacklee Herald.txt\", \"Alvarez PLC__0__0__L…\n$ text   &lt;chr&gt; \"Marine Sanctuary Aid Boosts Alvarez PLC's Sustainable Fishing …\n\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3261 documents and 0 docvars.\n# A data frame: 3,261 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,255 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\",\"Y\"),\n                       too_few = \"align_end\")"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html",
    "href": "In_class_ex/hands_on_ex1.html",
    "title": "Hands_on_ex1",
    "section": "",
    "text": "##Step 1: Installing the required libraries\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-in-histogram",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-in-histogram",
    "title": "Hands_on_ex1",
    "section": "Visualising data in Histogram",
    "text": "Visualising data in Histogram\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-in-dotplot",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-in-dotplot",
    "title": "Hands_on_ex1",
    "section": "Visualising data in Dotplot",
    "text": "Visualising data in Dotplot\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-in-histogram-in-bins",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-in-histogram-in-bins",
    "title": "Hands_on_ex1",
    "section": "Visualising data in Histogram in bins",
    "text": "Visualising data in Histogram in bins\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\nAdding colors\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-with-data-plotlines---geomdensity",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-with-data-plotlines---geomdensity",
    "title": "Hands_on_ex1",
    "section": "Visualising data with data plotlines - geomdensity()",
    "text": "Visualising data with data plotlines - geomdensity()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-with-boxplot-diagrams",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-with-boxplot-diagrams",
    "title": "Hands_on_ex1",
    "section": "Visualising data with Boxplot diagrams",
    "text": "Visualising data with Boxplot diagrams\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-with-violin-plot---geomviolin",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-with-violin-plot---geomviolin",
    "title": "Hands_on_ex1",
    "section": "Visualising data with violin plot - geomviolin()",
    "text": "Visualising data with violin plot - geomviolin()\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#visualising-data-in-scatterplot",
    "href": "In_class_ex/hands_on_ex1.html#visualising-data-in-scatterplot",
    "title": "Hands_on_ex1",
    "section": "Visualising data in scatterplot",
    "text": "Visualising data in scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#combining-boxplot-with-scatter-plot",
    "href": "In_class_ex/hands_on_ex1.html#combining-boxplot-with-scatter-plot",
    "title": "Hands_on_ex1",
    "section": "Combining boxplot with scatter plot",
    "text": "Combining boxplot with scatter plot\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#working-with-essential-grammatical-elements-in-ggplot2-stat",
    "href": "In_class_ex/hands_on_ex1.html#working-with-essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands_on_ex1",
    "section": "Working with Essential Grammatical Elements in ggplot2: stat",
    "text": "Working with Essential Grammatical Elements in ggplot2: stat\n\nWorking with stat summary\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\nOverriding soothing methods\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "In_class_ex/hands_on_ex1.html#working-with-essential-grammatical-elements-in-ggplot2-facet",
    "href": "In_class_ex/hands_on_ex1.html#working-with-essential-grammatical-elements-in-ggplot2-facet",
    "title": "Hands_on_ex1",
    "section": "Working with Essential Grammatical Elements in ggplot2: Facet",
    "text": "Working with Essential Grammatical Elements in ggplot2: Facet\n\nUsing Facetwraps\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\nUsing Facet Grid\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html",
    "href": "In_class_ex/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "",
    "text": "Learning Objectives:"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#installing-and-loading-the-required-libraries",
    "href": "In_class_ex/Hands-on_Ex05.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\nThe following R packages will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nCode chunk below will be used to check if these packages have been installed and also will load them into the working R environment.\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "In_class_ex/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nCreating a folder list\n\nnews20 &lt;- \"data/news20/\"\n\n\n\nDefine a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "In_class_ex/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Importing Multiple Text Files from Multiple Folders",
    "text": "Importing Multiple Text Files from Multiple Folders\n\nReading in all the messages from the 20news folder\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#initial-eda",
    "href": "In_class_ex/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Initial EDA",
    "text": "Initial EDA\nFigure below shows the frequency of messages by newsgroup.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#introducing-tidytext",
    "href": "In_class_ex/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Introducing tidytext",
    "text": "Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\n\nRemoving header and automated email signitures\nEach message contains certain structural elements and additional text that are undesirable for inclusion in the analysis. For example:\n\nHeader containing fields such as “from:” or “in_reply_to:”\nAutomated email signatures, which occur after a line like “–”.\n\nThe code chunk below uses:\n\ncumsum() of base R to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr to detect the presence or absence of a pattern in a string.\n\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\nRemoving lines with nested text representing quotes from other users\nRegular expressions are used to remove with nested text representing quotes from other users.\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\nText Data Processing\n\n unnest_tokens() of tidytext package is used to split the dataset into tokens\n stop_words() is used to remove stop-words\n\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nHeaders, signatures and formatting have been removed. The code chunk below calculates individual word frequncies to explore common words in the dataset.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nWord frequencies within newsgroup\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\nVisualising Words in newsgroups\n\nwordcloud() of wordcloud package is used to plot a static wordcloud\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\nTableCode\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a data frame with word frequency data\nword_freq_table &lt;- data.frame(Word = words_by_newsgroup$word,\n                              Frequency = words_by_newsgroup$n)\n\n# Render the DataTable\ndatatable(word_freq_table, \n          options = list(pageLength = 10))\n\n\n\n\n\n\nVisualising Words in newsgroups\n ggwordcloud package is used to plot the wordcloud below\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "In_class_ex/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "In_class_ex/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5 - Visualising and Analysing Text Data",
    "section": "Basic Concept of TF-IDF",
    "text": "Basic Concept of TF-IDF\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\\(idf(term) = ln \\frac{n_{documents}}{n_{documents containing term}}\\)\n\nComputing tf-idf within newsgroups\nbind_tf_idf() of tidytext is used to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\nVisualising tf-idf as interactive table\nInteractive table created by using datatable() to create a html table that allows pagination of rows and columns.\nThe code chunk below also uses:\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\nTableCode\n\n\n\n\n\n\n\n\n\n\n\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\nVisualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\nCounting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\nVisualising correlation as a network\nRelationship between newgroups is visualised as a network graph\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\nBigram\nCreated by using unnest_tokens() of tidytext.\n\nBigramCode\n\n\n\n\n# A tibble: 28,824 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,814 more rows\n\n\n\n\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\nbigrams\n\n\n\n\n\n\nCounting bigrams\nCount and sort the bigram data frame ascendingly\n\nBigram CountCode\n\n\n\n\n# A tibble: 19,885 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,875 more rows\n\n\n\n\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n\n\n\n\n\nCleaning bigram\nSeperate the bigram into two words\n\nBigramCode\n\n\n\n\n# A tibble: 4,604 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,594 more rows\n\n\n\n\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\n\n\n\n\nCounting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\n\n\n\nCreate a network graph from bigram data frame\nA network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 95ea16f DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 95ea16f (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\nVisualizing a network of bigrams with ggraph\nggraph package is used to plot the bigram\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\nRevised version\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html",
    "href": "take_home_ex/take_home_ex2.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "In this particular section, we will revisit Take-home Exercise 1 which visualises trends in the Real Estate Market of Q1 2024.\nWe will pick a visualisation which the author can learn from to improve on it’s clarity and aesthetics by way of using the best practices for visualizing data."
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#review",
    "href": "take_home_ex/take_home_ex2.html#review",
    "title": "Take Home Exercise 2",
    "section": "Review",
    "text": "Review\n\nThe GoodThe Not-So-Good\n\n\n\nThe interpretation of the data is very forward at a glance.\nThe results are also extremely straightforward, we are able to tell which property garners the highest volume of sales.\n\n\n\n\nThere is not much data nor further story telling to be had and this can be achieved easily with a simple excel function.\nThere is no interaction with the graphs hence, it is not possible to tell the exact numbers for each property type.\nIn addition, it is also possible to merge both of Aryan’s graph together such that they show a comprehensive picture of the private estate resale market."
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#how-might-we-do-it-differntly.",
    "href": "take_home_ex/take_home_ex2.html#how-might-we-do-it-differntly.",
    "title": "Take Home Exercise 2",
    "section": "How might we do it differntly.",
    "text": "How might we do it differntly.\nFirstly, we have to ascertain the story point which we would like to tell which is:\nWhat is the quaterly sales volume of each property type in Singapore?\nTo do that, we will need the following datapoints from the RELIS database:\n\nProperty Type\nSale Date\nTransacted Price ($)\n\nBroadly speaking, we will need to do the following data wrangling followed by visualisation:\n\nFirst is to bin the sale date of each transaction into the respective quarters\nPlot an initial bar graph of the quarterly sales volume\nPlot a second line graph showing the trend of the quarterly sales volume\nMerge the two graphs together with ggplot\nFinishing up with theming touches and interactions"
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#loading-the-required-packages",
    "href": "take_home_ex/take_home_ex2.html#loading-the-required-packages",
    "title": "Take Home Exercise 2",
    "section": "Loading the required packages",
    "text": "Loading the required packages\n\npacman::p_load(tidyverse, scales, DT, plotly, ggplot2)"
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#data-extraction",
    "href": "take_home_ex/take_home_ex2.html#data-extraction",
    "title": "Take Home Exercise 2",
    "section": "Data Extraction",
    "text": "Data Extraction\nFirst we will import the data from the 5 csv files from RELIS\n\n# Define the paths to the individual CSV files\nfile1 &lt;- \"data/ResidentialTransaction20240308160536.csv\"\nfile2 &lt;- \"data/ResidentialTransaction20240308160736.csv\"\nfile3 &lt;- \"data/ResidentialTransaction20240308161009.csv\"\nfile4 &lt;- \"data/ResidentialTransaction20240308161109.csv\"\nfile5 &lt;- \"data/ResidentialTransaction20240414220633.csv\"\n\n# Reading the individual CSV files\ndata1 &lt;- read_csv(file1)\ndata2 &lt;- read_csv(file2)\ndata3 &lt;- read_csv(file3)\ndata4 &lt;- read_csv(file4)\ndata5 &lt;- read_csv(file5)\n\n# Combining the data frames into one\ncombined_transaction &lt;- bind_rows(data1, data2, data3, data4, data5)\n\n# Viewing the data structure given\ncol_names &lt;- names(combined_transaction)\ncol_names\n\n [1] \"Project Name\"                \"Transacted Price ($)\"       \n [3] \"Area (SQFT)\"                 \"Unit Price ($ PSF)\"         \n [5] \"Sale Date\"                   \"Address\"                    \n [7] \"Type of Sale\"                \"Type of Area\"               \n [9] \"Area (SQM)\"                  \"Unit Price ($ PSM)\"         \n[11] \"Nett Price($)\"               \"Property Type\"              \n[13] \"Number of Units\"             \"Tenure\"                     \n[15] \"Completion Date\"             \"Purchaser Address Indicator\"\n[17] \"Postal Code\"                 \"Postal District\"            \n[19] \"Postal Sector\"               \"Planning Region\"            \n[21] \"Planning Area\"              \n\n\nSecondly, we will bin the data into Q1,Q2,Q3 and Q4\n\nCodechunkOutput\n\n\n\ncombined_transaction &lt;- combined_transaction %&gt;%\n  rename_with(~ gsub(\" \", \"_\", .), everything())\n\ncombined_transaction$Sale_Date &lt;- as.Date(combined_transaction$Sale_Date, format = \"%d %b %Y\")\ncombined_transaction$Quarter &lt;- paste(year(combined_transaction$Sale_Date), \"Q\", quarter(combined_transaction$Sale_Date), sep=\"\")\ncombined_transaction$Month &lt;- month(combined_transaction$Sale_Date, label = TRUE)\n\n\n\n\n\n\n\nWe will then use databtable to get a glimpse of our combined_transaction tibble\n\ndatatable(head(combined_transaction, n = 20))"
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#data-wrangling",
    "href": "take_home_ex/take_home_ex2.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nPlotting initial graph\nThe initial graph shall be a barchart which shows the Number of Transactions by each Quarter\n\n# Plotting transactions by property type across quarters\nggplot(combined_transaction, aes(x = Quarter, fill = Property_Type)) +\n  geom_bar(stat = \"count\", position = \"dodge\") +\n  labs(title = \"Transactions  by Property Type from Q1 2023 to Q1 2024\",\n       x = \"Quarter\",\n       y = \"Number of Transactions\",\n       fill = \"Property Type\") +\n  theme_minimal()\n\n\n\n\n\n\nPlotting secondary graph\nThe secondary graph shall show the line trend of the Number of Transactions by each Quarter.\n\naggregated_data &lt;- combined_transaction %&gt;%\n  group_by(Quarter, Property_Type) %&gt;%\n  summarise(Transactions = n(), .groups = 'drop')  # `n()` counts the number of rows in each group\n\n# Plotting transactions by property type across quarters using a line graph\nggplot(aggregated_data, aes(x = Quarter, y = Transactions, color = Property_Type, group = Property_Type)) +\n  geom_line() +  # Adds lines\n  geom_point() + # Adds points at each data entry\n  labs(title = \"Transactions by Property Type from Q1 2023 to Q1 2024\",\n       x = \"Quarter\",\n       y = \"Number of Transactions\",\n       color = \"Property Type\") +\n  theme_minimal() # Improve label readability\n\n\n\n\n\n\nCombining it together\nWe will then merge both the graphs together to have a clear picture of each quarter’s transactions volumes\n\n# Getting the mean number for each property transaction for all quarters\n  average_data &lt;- aggregated_data %&gt;%\n  group_by(Property_Type) %&gt;%\n  summarise(Average_Transactions = mean(Transactions))\n  \n# Start with the bar graph\np &lt;- ggplot(aggregated_data, aes(x = Quarter, y = Transactions, fill = Property_Type)) +\n  geom_bar(stat = \"identity\", position = position_dodge(), width = 0.6) +  # Draw the bars\n\n  # Add the line graph\n  geom_line(aes(group = Property_Type, color = Property_Type), \n            position = position_dodge(0.6), size = 0.5) +\n  \n  # Adding mean line\ngeom_hline(data = average_data, aes(yintercept = Average_Transactions, color = Property_Type, \n                                      text = paste(\"Property Type:\", Property_Type, \n                                            \"&lt;br&gt;Average Transactions:\", Average_Transactions)),\nlinetype = \"dashed\", size = 0.35) +\n  # Labels and themes\n  labs(title = \"Transactions by Property Type from Q1 2023 to Q1 2024\",\n       x = \"Quarter\",\n       y = \"Number of Transactions\",\n       fill = \"Property Type\",\n       color = \"Property Trend Line\") +\n  theme_minimal() \n\n# Print the plot\np\n\n\n\n\n\n\nFinishing touches with Interaction using Plotly\nFinally we will add in Plotly’s interactive capability.\n\nCodechunkOutput\n\n\n\n# Convert the ggplot object to a plotly object\np_interactive &lt;- ggplotly(p, tooltip = \"text\")\n\n# Customize the hoverlabel for better appearance\np_interactive &lt;- layout(p_interactive, hoverlabel = list(bgcolor = \"white\"))\n\n# Print the interactive plot\np_interactive"
  },
  {
    "objectID": "take_home_ex/take_home_ex2.html#conclusion",
    "href": "take_home_ex/take_home_ex2.html#conclusion",
    "title": "Take Home Exercise 2",
    "section": "Conclusion",
    "text": "Conclusion\nWith our own interpretation translated into amendments on Arya Siahaan visualization completed above, below is a recap on the changes we have done and reasoning for the associated\n\n\n\n\n\n\n\n\nS\\N\nAryan’s Visusalisation Element\nOur Changes\n\n\n\n\n1\n2 seperate bar graphs to showcase monthly sales volume and it’s distribution by property type.\nUsing ggplot library to merge both sets of visualization into a single graph so that end users will not have to scroll between 2 graphs to make the reconciliation\n\n\n2\nMono color scheme for different property types represented in a bar graph\nUsing ggplot’s themes to segregate property types into colors for easier identification\n\n\n3\nSales volume transaction is represented in different months instead of Quarters\nBinned transactions into their respective quarters for ease of comparison as required by the Professor.\n\n\n4\nStatic data visualization\nAdded plotly’s interactive elements such that onhover, detailed transaction numbers can be taken immediately.\n\n\n5\nMean line for total sales’ volume graph only\nSegregated each property types’ mean transaction for all 5 quarters"
  }
]